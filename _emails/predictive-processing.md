---
subtitle:
date: 2022-04-20
tags: psychology AI computers research learning
---

# Predictive Processing and the Free Energy Principle

## Terms:
- Active inference
-  [Predictive Processing/Predictive Coding](https://en.wikipedia.org/wiki/Predictive_coding)
-  [Free Energy Principle](https://en.wikipedia.org/wiki/Free_energy_principle)
-  [Markov Blanket](https://en.wikipedia.org/wiki/Markov_blanket)
-  [Model of Action](https://en.wikipedia.org/wiki/Theory_of_reasoned_action)

## Classical model of action:
- Optimal action depends on state of the world 
- Therefore, first step of action is to (1) form a belief (analyse surroundings/prospects)
- (2) imagine a value function of next state brought about by action
- (3) optimise action that maximises value of the next state

## Model of action
- Classical model doesn't work when the best next thing to do is to search for/resolve uncertainty
- Optimal action depends on beliefs about the world, and subsequent action
- Further, it's a function of the order in which you interrogate the world
- Therefore the functional (function of a function) to be optimised is a function of beliefs
- Optimal action therefore is optimising sequences or policies of actions
- To be optimised: a function of a belief, integrated over time

## Free Energy Principle:

- The goal of a self-organising (eg biological) system is to minimise prediction error (surprise), also called 'free energy', by forming continually-updated beliefs/inferences about the world from which to form policies of action
- Friston considers this an organising principle of all life and intelligence
- To be alive (to be a system that resists disorder and dissolution) is to act in ways that reduce the gulf between your expectations and your sensory inputs (AKA, to minimise free energy)

- If a prototypical agent, or a 'good agent' minimises free energy (thereby minimising 'surprise'), they must believe that the actions they take minimised expected free energy
- expected free energy associated with a policy of action is minimised



## Markov Blanket:
The Markov Blanket is a concept in machine learning which is essentially a shield that separates one set of variables from others in a layered, hierarchical system. The blanket defines the boundaries of a given system. That is, in cognition, a cognitive version of a cell membrane shielding states inside the blanket from states outside. This is the schema by which surprise is minimisedâ€” the Markov blanket is a set of variables sufficiently complete that another random variable can be inferred from it . If a Markov blanket is minimal (parsimonious) (cannot drop any variable without losing information), it is called a Markov boundary.




